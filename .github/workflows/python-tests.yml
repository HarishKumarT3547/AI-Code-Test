name: Python Tests comment Generator

on:
  pull_request:
    branches: [main, master]

# Add permissions block
permissions:
  pull-requests: write
  contents: write

jobs:
  test:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: ["3.10"]

    steps:
      - uses: actions/checkout@v3
        with:
          fetch-depth: 0 # Required for diff coverage
          ref: ${{ github.head_ref }} # Checkout the PR branch

      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v4
        with:
          python-version: ${{ matrix.python-version }}

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pytest pytest-cov pylint black diff-cover

      - name: Lint with pylint
        run: |
          pylint src/ --output-format=json || true

      - name: Check formatting with black
        run: |
          black --check src/ || true

      - name: Run tests with pytest
        run: |
          python -m pytest src/ --cov=src --cov-report=xml --cov-report=term-missing --cov-report=html

      - name: Check diff coverage
        run: |
          # Fetch the base branch
          git fetch origin ${{ github.base_ref }}

          # Run diff coverage against the base branch
          diff-cover coverage.xml --compare-branch=origin/${{ github.base_ref }} --html-report report.html

          # Extract uncovered lines
          UNCOVERED_LINES=$(diff-cover coverage.xml --compare-branch=origin/${{ github.base_ref }} --json-report report.json)

          # Save uncovered lines to a file
          echo "$UNCOVERED_LINES" > uncovered_lines.txt

          # Generate the comment body with specific test suggestions
          echo "## Missing Test Coverage Analysis" > comment_body.md
          echo "### Coverage Summary" >> comment_body.md
          echo "$UNCOVERED_LINES" | grep "Total:" -A 3 >> comment_body.md
          echo "" >> comment_body.md

          echo "### Detailed Test Suggestions" >> comment_body.md

          # Process each file's uncovered lines
          while IFS= read -r line; do
            if [[ $line == *"src/"* ]]; then
              FILE=$(echo $line | cut -d':' -f1)
              FILENAME=$(basename "$FILE")
              MODULE_NAME="${FILENAME%.*}"
              LINES=$(echo $line | cut -d':' -f2-)
              
              echo "#### $FILE" >> comment_body.md
              echo "Uncovered lines: $LINES" >> comment_body.md
              echo "" >> comment_body.md
              
              # Generate test suggestions based on line numbers
              echo "**Suggested Test Cases:**" >> comment_body.md
              echo '```python' >> comment_body.md
              echo "def test_${MODULE_NAME}_coverage():" >> comment_body.md
              echo "    # Test setup" >> comment_body.md
              echo "    test_data = {" >> comment_body.md
              
              # Add test data based on line numbers
              if [[ "$LINES" == *"90-95"* ]]; then
                echo "        # Test data for lines 90-95" >> comment_body.md
                echo "        'null_input': None," >> comment_body.md
                echo "        'valid_input': {'key': 'value'}," >> comment_body.md
              fi
              
              if [[ "$LINES" == *"111"* || "$LINES" == *"116"* ]]; then
                echo "        # Test data for lines 111,116" >> comment_body.md
                echo "        'empty_list': []," >> comment_body.md
                echo "        'single_item': [1]," >> comment_body.md
                echo "        'multiple_items': [1, 2, 3]," >> comment_body.md
              fi
              
              if [[ "$LINES" == *"119"* || "$LINES" == *"127-128"* ]]; then
                echo "        # Test data for lines 119,127-128" >> comment_body.md
                echo "        'valid_input': 'valid'," >> comment_body.md
                echo "        'invalid_input': None," >> comment_body.md
              fi
              
              echo "    }" >> comment_body.md
              echo "" >> comment_body.md
              echo "    # Test cases" >> comment_body.md
              echo "    for scenario, data in test_data.items():" >> comment_body.md
              echo "        with pytest.subTest(scenario=scenario):" >> comment_body.md
              echo "            result = function_to_test(data)" >> comment_body.md
              echo "            assert result is not None" >> comment_body.md
              echo '```' >> comment_body.md
              echo "" >> comment_body.md
            fi
          done <<< "$UNCOVERED_LINES"

      - name: Create test files
        run: |
          # Create Python script
          echo 'import os' > generate_tests.py
          echo 'import re' >> generate_tests.py
          echo 'from datetime import datetime' >> generate_tests.py
          echo '' >> generate_tests.py
          echo 'def sanitize_filename(name):' >> generate_tests.py
          echo '    # Remove any non-alphanumeric characters except underscores' >> generate_tests.py
          echo '    return re.sub(r"[^a-zA-Z0-9_]", "_", name)' >> generate_tests.py
          echo '' >> generate_tests.py
          echo 'def generate_test_file(module_name, lines):' >> generate_tests.py
          echo '    # Create test recommendations directory if it doesnt exist' >> generate_tests.py
          echo '    test_dir = "src/test_recommendations"' >> generate_tests.py
          echo '    os.makedirs(test_dir, exist_ok=True)' >> generate_tests.py
          echo '' >> generate_tests.py
          echo '    # Create a valid Python module name with timestamp' >> generate_tests.py
          echo '    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")' >> generate_tests.py
          echo '    sanitized_name = sanitize_filename(module_name)' >> generate_tests.py
          echo '    test_module_name = f"test_{sanitized_name}_{timestamp}"' >> generate_tests.py
          echo '    test_file = os.path.join(test_dir, f"{test_module_name}.py")' >> generate_tests.py
          echo '' >> generate_tests.py
          echo '    # Check if file exists and delete it' >> generate_tests.py
          echo '    if os.path.exists(test_file):' >> generate_tests.py
          echo '        os.remove(test_file)' >> generate_tests.py
          echo '' >> generate_tests.py
          echo '    with open(test_file, "w") as f:' >> generate_tests.py
          echo '        f.write(f"""import pytest' >> generate_tests.py
          echo 'import sys' >> generate_tests.py
          echo 'import os' >> generate_tests.py
          echo 'sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))' >> generate_tests.py
          echo 'from {module_name} import *' >> generate_tests.py
          echo '' >> generate_tests.py
          echo 'def test_{sanitized_name}_coverage():' >> generate_tests.py
          echo '    # Test setup' >> generate_tests.py
          echo '    test_data = {{' >> generate_tests.py
          echo '' >> generate_tests.py
          echo '        # Test data for lines 90-95' >> generate_tests.py
          echo "        'null_input': None," >> generate_tests.py
          echo "        'valid_input': {'key': 'value'}," >> generate_tests.py
          echo '' >> generate_tests.py
          echo '        # Test data for lines 111,116' >> generate_tests.py
          echo "        'empty_list': []," >> generate_tests.py
          echo "        'single_item': [1]," >> generate_tests.py
          echo "        'multiple_items': [1, 2, 3]," >> generate_tests.py
          echo '' >> generate_tests.py
          echo '        # Test data for lines 119,127-128' >> generate_tests.py
          echo "        'valid_input': 'valid'," >> generate_tests.py
          echo "        'invalid_input': None," >> generate_tests.py
          echo '    }}' >> generate_tests.py
          echo '' >> generate_tests.py
          echo '    # Test cases' >> generate_tests.py
          echo '    for scenario, data in test_data.items():' >> generate_tests.py
          echo '        with pytest.subTest(scenario=scenario):' >> generate_tests.py
          echo '            result = function_to_test(data)' >> generate_tests.py
          echo '            assert result is not None' >> generate_tests.py
          echo '""")' >> generate_tests.py
          echo '' >> generate_tests.py
          echo '# Process uncovered lines' >> generate_tests.py
          echo 'with open("uncovered_lines.txt", "r") as f:' >> generate_tests.py
          echo '    for line in f:' >> generate_tests.py
          echo '        if "src/" in line:' >> generate_tests.py
          echo '            file_path = line.split(":")[0]' >> generate_tests.py
          echo '            module_name = os.path.splitext(os.path.basename(file_path))[0]' >> generate_tests.py
          echo '            lines = line.split(":")[1]' >> generate_tests.py
          echo '            generate_test_file(module_name, lines)' >> generate_tests.py

          # Run the Python script
          python3 generate_tests.py

      - name: Create PR comment
        uses: actions/github-script@v6
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const fs = require('fs');
            try {
              const commentBody = fs.readFileSync('comment_body.md', 'utf8');
              
              // Create a new comment
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: context.issue.number,
                body: commentBody
              });
            } catch (error) {
              console.error('Error creating comment:', error);
              process.exit(0);
            }

      - name: Commit test files
        if: always()
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          # Check if any test files were created
          if [ -n "$(find src/test_recommendations -name 'test_*.py')" ]; then
            git add src/test_recommendations/
            git commit -m "Add test coverage recommendations"
            git push origin HEAD:${{ github.head_ref }}
          else
            echo "No test files were created to commit"
          fi

      - name: Upload coverage to Codecov
        if: always() # Run this step even if previous steps fail
        uses: codecov/codecov-action@v3
        with:
          file: ./coverage.xml
          fail_ci_if_error: false # Don't fail the workflow if upload fails
          token: ${{ secrets.CODECOV_TOKEN }} # Use repository token if available
          flags: unittests # Add a flag to identify these coverage reports
          name: codecov-umbrella # Give the upload a name
          verbose: true # Get more detailed logs

      - name: Upload coverage report as artifact
        if: always() # Run this step even if previous steps fail
        uses: actions/upload-artifact@v4
        with:
          name: coverage-report
          path: |
            coverage.xml
            htmlcov/
            report.html
          retention-days: 5
